from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import Select
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import json
import time
import random
import os


class FoodSafetyDataScraper:
    def __init__(self):
        # è¨­å®šChromeé¸é …
        options = webdriver.ChromeOptions()

        # æ·»åŠ User-Agentä¾†æ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨
        options.add_argument(
            "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )

        # ç¦ç”¨è‡ªå‹•åŒ–æ¨™è¨˜
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)

        # å…¶ä»–é¸é …
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--no-sandbox")

        # å¦‚æœä¸æƒ³çœ‹åˆ°ç€è¦½å™¨è¦–çª—ï¼Œå¯ä»¥å–æ¶ˆè¨»è§£ä¸‹é¢é€™è¡Œ
        # options.add_argument('--headless')

        self.driver = webdriver.Chrome(options=options)
        self.wait = WebDriverWait(self.driver, 20)
        self.all_data = []

    def random_sleep(self, min_sec=1, max_sec=3):
        """éš¨æ©Ÿå»¶é²ï¼Œæ¨¡æ“¬äººé¡è¡Œç‚º"""
        time.sleep(random.uniform(min_sec, max_sec))

    def open_page_and_wait(self):
        """é–‹å•Ÿç¶²é ä¸¦ç­‰å¾…ä½¿ç”¨è€…æ‰‹å‹•å®ŒæˆæŸ¥è©¢"""
        try:
            print(f"\n{'='*60}")
            print(f"æ‰‹å‹•æŸ¥è©¢æ¨¡å¼")
            print(f"{'='*60}")

            # é–‹å•Ÿç¶²é 
            print("  > æ­£åœ¨é–‹å•Ÿç¶²é ...")
            self.driver.get("https://imap.health.gov.tw/App_Prog/Analysis3.aspx")
            self.random_sleep(2, 3)
            print("  âœ“ ç¶²é å·²é–‹å•Ÿ")

            print("\n" + "=" * 60)
            print("è«‹åœ¨ç€è¦½å™¨ä¸­æ‰‹å‹•å®Œæˆä»¥ä¸‹æ“ä½œï¼š")
            print("  1. è¨­å®šèµ·å§‹æ—¥æœŸï¼ˆä¾‹å¦‚ï¼š2025-01-01ï¼‰")
            print("  2. è¨­å®šçµæŸæ—¥æœŸï¼ˆä¾‹å¦‚ï¼š2025-12-29ï¼‰")
            print("  3. é»æ“Šã€æŸ¥è©¢ã€‘æŒ‰éˆ•")
            print("  4. ç­‰å¾…æŸ¥è©¢çµæœé¡¯ç¤ºå‡ºä¾†")
            print("=" * 60)

            input("\nå®Œæˆå¾ŒæŒ‰ Enter éµç¹¼çºŒçˆ¬èŸ²...")
            print("\n" + "=" * 60)
            print("é–‹å§‹è‡ªå‹•æŠ“å–è³‡æ–™")
            print("=" * 60 + "\n")
            return True

        except Exception as e:
            print(f"  âœ— é–‹å•Ÿç¶²é æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback

            traceback.print_exc()
            return False

    def setup_date_and_search(self, start_date="2025-01-01", end_date="2025-12-29"):
        """è¨­å®šæ—¥æœŸä¸¦åŸ·è¡ŒæŸ¥è©¢"""
        try:
            print(f"\n{'='*60}")
            print(f"æ­¥é©Ÿ 1: é–‹å•Ÿç¶²é ä¸¦è¨­å®šæŸ¥è©¢æ¢ä»¶")
            print(f"{'='*60}")

            # é–‹å•Ÿç¶²é 
            print("  > æ­£åœ¨è¼‰å…¥ç¶²é ...")
            self.driver.get("https://imap.health.gov.tw/App_Prog/Analysis3.aspx")
            self.random_sleep(3, 5)
            print("  âœ“ ç¶²é è¼‰å…¥å®Œæˆ")

            # è¨­å®šèµ·å§‹æ—¥æœŸ
            print(f"  > è¨­å®šèµ·å§‹æ—¥æœŸ: {start_date}")
            start_date_input = self.wait.until(
                EC.presence_of_element_located(
                    (
                        By.ID,
                        "ContentPlaceHolder1_ContentPlaceHolder2_uccheck_dateS_cxtDateYMD",
                    )
                )
            )
            start_date_input.clear()
            self.random_sleep(0.3, 0.5)
            start_date_input.send_keys(start_date)
            self.random_sleep(0.5, 1)
            print(f"  âœ“ èµ·å§‹æ—¥æœŸå·²è¨­å®šç‚º {start_date}")

            # è¨­å®šçµæŸæ—¥æœŸ
            print(f"  > è¨­å®šçµæŸæ—¥æœŸ: {end_date}")
            end_date_input = self.driver.find_element(
                By.ID,
                "ContentPlaceHolder1_ContentPlaceHolder2_uccheck_dateE_cxtDateYMD",
            )
            end_date_input.clear()
            self.random_sleep(0.3, 0.5)
            end_date_input.send_keys(end_date)
            self.random_sleep(0.5, 1)
            print(f"  âœ“ çµæŸæ—¥æœŸå·²è¨­å®šç‚º {end_date}")

            # é»æ“ŠæŸ¥è©¢æŒ‰éˆ•
            print("  > é»æ“ŠæŸ¥è©¢æŒ‰éˆ•...")
            search_btn = self.wait.until(
                EC.element_to_be_clickable((By.ID, "btnSearch"))
            )
            search_btn.click()
            print("  âœ“ æŸ¥è©¢æŒ‰éˆ•å·²é»æ“Š")

            # ç­‰å¾…æŸ¥è©¢çµæœè¼‰å…¥
            print("  > ç­‰å¾…æŸ¥è©¢çµæœè¼‰å…¥...")
            self.random_sleep(4, 6)

            # ç¢ºèªæŸ¥è©¢çµæœå·²è¼‰å…¥
            try:
                self.wait.until(
                    EC.text_to_be_present_in_element((By.ID, "num_1"), "å®¶")
                )
                print("  âœ“ æŸ¥è©¢çµæœè¼‰å…¥å®Œæˆ\n")
                print(f"{'='*60}")
                print(f"æ­¥é©Ÿ 2: é–‹å§‹æŠ“å–å„æ¥­åˆ¥è³‡æ–™")
                print(f"{'='*60}\n")
                return True
            except TimeoutException:
                print("  âœ— æŸ¥è©¢çµæœè¼‰å…¥é€¾æ™‚")
                return False

        except Exception as e:
            print(f"  âœ— è¨­å®šæŸ¥è©¢æ¢ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback

            traceback.print_exc()
            return False

    def click_category(self, category_id):
        """é»æ“Šç‰¹å®šæ¥­åˆ¥"""
        try:
            category_link = self.wait.until(
                EC.element_to_be_clickable((By.ID, category_id))
            )
            self.driver.execute_script(
                "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});",
                category_link,
            )
            self.random_sleep(0.5, 1)
            category_link.click()
            self.random_sleep(2, 3)
            return True
        except Exception as e:
            print(f"  âœ— é»æ“Šæ¥­åˆ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def set_page_size(self, size=50):
        """è¨­å®šæ¯é é¡¯ç¤ºç­†æ•¸"""
        try:
            page_size_select_element = self.wait.until(
                EC.presence_of_element_located(
                    (
                        By.ID,
                        "ContentPlaceHolder1_ContentPlaceHolder2_ucPageDividerPHPS1_uDdlPageSize",
                    )
                )
            )
            self.driver.execute_script(
                "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});",
                page_size_select_element,
            )
            self.random_sleep(0.5, 1)

            page_size_select = Select(page_size_select_element)
            page_size_select.select_by_value(str(size))
            self.random_sleep(2, 3)
            print(f"    > å·²è¨­å®šæ¯é é¡¯ç¤º {size} ç­†")
            return True
        except Exception as e:
            print(f"    ! ç„¡æ³•è¨­å®šé é¢å¤§å°: {e}")
            return False

    def get_current_page_data(self):
        """ç²å–ç•¶å‰é é¢çš„è³‡æ–™"""
        data_list = []
        try:
            table = self.wait.until(
                EC.presence_of_element_located(
                    (By.ID, "ContentPlaceHolder1_ContentPlaceHolder2_gvSearchList")
                )
            )

            rows = table.find_elements(By.TAG_NAME, "tr")[1:]  # è·³éè¡¨é ­

            for row in rows:
                try:
                    cells = row.find_elements(By.TAG_NAME, "td")
                    if len(cells) >= 3:
                        company_name = cells[0].text.strip()
                        address = cells[1].text.strip()
                        registration_number = cells[2].text.strip()

                        if company_name and registration_number:
                            data = {
                                "company_name": company_name,
                                "address": address,
                                "registration_number": registration_number,
                            }
                            data_list.append(data)
                except Exception as e:
                    continue

            return data_list

        except Exception as e:
            print(f"    âœ— ç²å–é é¢è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def has_next_page(self):
        """æª¢æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é """
        try:
            next_btn_container = self.driver.find_element(
                By.ID,
                "ContentPlaceHolder1_ContentPlaceHolder2_ucPageDividerPHPS1_uLkbNext",
            ).find_element(By.XPATH, "..")

            return "aspNetDisabled" not in next_btn_container.get_attribute("class")
        except:
            return False

    def click_next_page(self):
        """é»æ“Šä¸‹ä¸€é """
        try:
            next_btn = self.wait.until(
                EC.element_to_be_clickable(
                    (
                        By.ID,
                        "ContentPlaceHolder1_ContentPlaceHolder2_ucPageDividerPHPS1_uLkbNext",
                    )
                )
            )
            self.driver.execute_script(
                "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});",
                next_btn,
            )
            self.random_sleep(0.5, 1)
            next_btn.click()
            self.random_sleep(2, 3)
            return True
        except Exception as e:
            return False

    def scrape_category(self, category_id, category_name):
        """æŠ“å–ç‰¹å®šæ¥­åˆ¥çš„æ‰€æœ‰è³‡æ–™"""
        print(f"\n[{category_name}]")
        print(f"  > é»æ“Šæ¥­åˆ¥æŒ‰éˆ•...")

        if not self.click_category(category_id):
            print(f"  âœ— ç„¡æ³•é»æ“Šæ¥­åˆ¥æŒ‰éˆ•")
            return []

        print(f"  âœ“ æ¥­åˆ¥åˆ‡æ›æˆåŠŸ")

        # è¨­å®šæ¯é é¡¯ç¤º50ç­†
        self.set_page_size(50)

        category_data = []
        page_num = 1

        while True:
            print(f"    > æ­£åœ¨æŠ“å–ç¬¬ {page_num} é ...")
            page_data = self.get_current_page_data()

            if page_data:
                category_data.extend(page_data)
                print(f"    âœ“ ç¬¬ {page_num} é å®Œæˆï¼Œç²å– {len(page_data)} ç­†è³‡æ–™")

                # å¦‚æœç•¶å‰é è³‡æ–™å°‘æ–¼50ç­†ï¼Œè¡¨ç¤ºæ˜¯æœ€å¾Œä¸€é ï¼Œä¸éœ€è¦å†ç¿»é 
                if len(page_data) < 50:
                    print(f"    âœ“ ç•¶å‰é è³‡æ–™å°‘æ–¼ 50 ç­†ï¼Œå·²åˆ°æœ€å¾Œä¸€é ")
                    break
            else:
                print(f"    ! ç¬¬ {page_num} é æ²’æœ‰è³‡æ–™")
                break

            # æª¢æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é æŒ‰éˆ•ä¸”å¯é»æ“Š
            if self.has_next_page():
                if self.click_next_page():
                    page_num += 1
                else:
                    print(f"    ! ç„¡æ³•åˆ‡æ›åˆ°ä¸‹ä¸€é ï¼Œåœæ­¢æŠ“å–")
                    break
            else:
                print(f"    âœ“ å·²ç¶“æ˜¯æœ€å¾Œä¸€é ")
                break

        print(f"  âœ“ [{category_name}] å®Œæˆï¼Œå…± {len(category_data)} ç­†è³‡æ–™")
        return category_data

    def scrape_all_categories(self, manual_mode=False):
        """æŠ“å–æ‰€æœ‰æ¥­åˆ¥çš„è³‡æ–™"""
        categories = [
            ("A_1", "é¤ç›’é£Ÿå“"),
            ("A_2", "å­¸æ ¡åŠæ©Ÿé—œé™„è¨­å»šæˆ¿"),
            ("A_3", "è‡ªåŠ©é¤é£²åŠå¤–ç‡´é£²é£Ÿæ¥­"),
            ("A_4", "çƒ˜ç„™æ¥­"),
            ("A_5", "æ—©é¤é€Ÿé£Ÿæ¥­"),
            ("A_6", "é£²æ–™æ¥­"),
            ("A_7", "è§€å…‰é£¯åº—"),
            ("A_8", "å…¶ä»–"),
        ]

        # æ ¹æ“šæ¨¡å¼é¸æ“‡è¨­å®šæ–¹å¼
        if manual_mode:
            if not self.open_page_and_wait():
                print("\nâœ— ç„¡æ³•é–‹å•Ÿç¶²é ï¼Œç¨‹å¼çµ‚æ­¢")
                return
        else:
            if not self.setup_date_and_search():
                print("\nâœ— ç„¡æ³•å®ŒæˆæŸ¥è©¢è¨­å®šï¼Œç¨‹å¼çµ‚æ­¢")
                return

        # é–‹å§‹æŠ“å–å„æ¥­åˆ¥
        for idx, (category_id, category_name) in enumerate(categories, 1):
            try:
                print(f"\né€²åº¦: [{idx}/{len(categories)}]")
                data = self.scrape_category(category_id, category_name)
                self.all_data.extend(data)
                print(f"  ç´¯è¨ˆå·²æŠ“å–: {len(self.all_data)} ç­†è³‡æ–™")
                self.random_sleep(1, 2)
            except Exception as e:
                print(f"  âœ— æŠ“å– {category_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                import traceback

                traceback.print_exc()
                continue

        print(f"\n{'='*60}")
        print(f"æ‰€æœ‰è³‡æ–™æŠ“å–å®Œæˆï¼")
        print(f"ç¸½å…±ç²å– {len(self.all_data)} ç­†è³‡æ–™")
        print(f"{'='*60}\n")

    def save_to_json(self, filename="food_business_data.json"):
        """å„²å­˜è³‡æ–™åˆ°JSONæª”æ¡ˆ"""
        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(self.all_data, f, ensure_ascii=False, indent=2)

            abs_path = os.path.abspath(filename)
            print(f"âœ“ è³‡æ–™å·²å„²å­˜è‡³: {abs_path}")
            print(f"  ç¸½ç­†æ•¸: {len(self.all_data)}")
            return True
        except Exception as e:
            print(f"âœ— å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def close(self):
        """é—œé–‰ç€è¦½å™¨"""
        try:
            self.driver.quit()
            print("âœ“ ç€è¦½å™¨å·²é—œé–‰")
        except:
            pass


def main():
    print("\n" + "=" * 60)
    print("é£Ÿå“æ¥­è€…è³‡æ–™çˆ¬èŸ²ç¨‹å¼")
    print("=" * 60)

    # è©¢å•ä½¿ç”¨è€…è¦ä½¿ç”¨å“ªç¨®æ¨¡å¼
    print("\nè«‹é¸æ“‡æ“ä½œæ¨¡å¼ï¼š")
    print("  1. è‡ªå‹•æ¨¡å¼ï¼ˆç¨‹å¼è‡ªå‹•è¨­å®šæ—¥æœŸä¸¦æŸ¥è©¢ï¼‰")
    print("  2. æ‰‹å‹•æ¨¡å¼ï¼ˆæ‚¨æ‰‹å‹•å®ŒæˆæŸ¥è©¢å¾Œï¼Œç¨‹å¼å†é–‹å§‹çˆ¬èŸ²ï¼‰")

    while True:
        choice = input("\nè«‹è¼¸å…¥ 1 æˆ– 2: ").strip()
        if choice in ["1", "2"]:
            break
        print("âŒ è«‹è¼¸å…¥ 1 æˆ– 2")

    manual_mode = choice == "2"

    if not manual_mode:
        print("\nğŸ“… æ—¥æœŸç¯„åœ: 2025-01-01 ~ 2025-12-29")

    print("=" * 60)

    scraper = None

    try:
        scraper = FoodSafetyDataScraper()

        # æŠ“å–æ‰€æœ‰æ¥­åˆ¥è³‡æ–™
        scraper.scrape_all_categories(manual_mode=manual_mode)

        # å„²å­˜åˆ°JSONæª”æ¡ˆ
        if scraper.all_data:
            scraper.save_to_json("food_business_data.json")

            # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
            print("\nçµ±è¨ˆè³‡è¨Š:")
            print(f"  ç¸½ç­†æ•¸: {len(scraper.all_data)}")

            # é¡¯ç¤ºå‰3ç­†è³‡æ–™é è¦½
            if len(scraper.all_data) > 0:
                print(f"\nå‰3ç­†è³‡æ–™é è¦½:")
                for i, item in enumerate(scraper.all_data[:3], 1):
                    print(
                        f"  {i}. {item['company_name']} - {item['registration_number']}"
                    )
        else:
            print("\nâš  æ²’æœ‰æŠ“å–åˆ°ä»»ä½•è³‡æ–™")

    except KeyboardInterrupt:
        print("\n\nâš  ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
    except Exception as e:
        print(f"\nâœ— åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback

        traceback.print_exc()
    finally:
        if scraper:
            scraper.close()
        print("\nç¨‹å¼çµæŸ")


if __name__ == "__main__":
    main()
