"""
food_safety_classifier.py
é£Ÿå“å®‰å…¨é¢¨éšªåˆ†ç´šæ¨¡çµ„ï¼ˆæ•´åˆå®˜æ–¹è©•æ ¸è³‡æ–™ï¼‰

åŠŸèƒ½ï¼š
1. åˆ†æ Google Places è©•è«–ä¸­çš„é£Ÿå®‰é¢¨éšªé—œéµå­—
2. æ¯”å°å°åŒ—å¸‚æ”¿åºœé¤é£²è¡›ç”Ÿç®¡ç†åˆ†ç´šè©•æ ¸è³‡æ–™ï¼ˆåƒ…é™ã€Œå„ªã€ç­‰ç´šï¼‰
3. è¼¸å‡ºæ•´åˆå¾Œçš„é¢¨éšªåˆ†ç´šå ±å‘Š

ä½¿ç”¨æ–¹å¼ï¼š
    python food_safety_classifier.py

è¼¸å…¥æª”æ¡ˆï¼š
    - data/raw/places_with_reviews.jsonï¼ˆçˆ¬èŸ²è³‡æ–™ï¼‰
    - data/external/certified_restaurants.csvï¼ˆå®˜æ–¹è©•æ ¸è³‡æ–™ï¼‰

è¼¸å‡ºæª”æ¡ˆï¼š
    - data/processed/safety_classified.json
"""
import json
import csv
import os
from typing import List, Dict, Any, Optional
from enum import Enum
from datetime import datetime


# ====================
# å¸¸æ•¸å®šç¾©
# ====================
class SafetyLevel(Enum):
    """é£Ÿå®‰é¢¨éšªç­‰ç´š"""
    HIGH_RISK = "é«˜é¢¨éšª"
    MEDIUM_RISK = "ä¸­é¢¨éšª"
    LOW_RISK = "ç„¡/ä½é¢¨éšª"
    CERTIFIED = "å®˜æ–¹èªè­‰"


# 1. è² é¢ç—‡ç‹€ã€æ„Ÿå®˜ç•°ç‹€èˆ‡ç‰©ç†å±å®³ï¼ˆåƒäº†å‡ºå•é¡Œ / User è² é¢é«”æ„Ÿå›é¥‹ï¼‰
SYMPTOM_KEYWORDS = [
    # æ€¥æ€§ç—…å¾µ
    "ç™¼ç‡’", "è™›å¼±", "é ­æšˆ", "å†’å†·æ±—", "è‚Œè‚‰é…¸ç—›", "ç™¼å†·",
    "å˜”å", "å™å¿ƒ", "èƒƒç—™æ”£", "ä¸Šåä¸‹ç€‰",
    "æ‹‰è‚šå­", "è…¹ç€‰", "è‚šå­ç—›", "ç‹‚æ‹‰", "ç‹‚ç€‰", "è·‘å»æ‰€", "è…¹çµç—›",
    "ç´…ç–¹", "éæ•",
    "çœ‹é†«ç”Ÿ", "æ›æ€¥è¨º", "è…¸èƒƒç‚", "é£Ÿç‰©ä¸­æ¯’", 
    
    # æ„Ÿå®˜ç•°ç‹€ (å—…è¦º/å‘³è¦º)
    "ä¸æ–°é®®", "è‡­æ‰", "å£æ‰", "ç™¼éœ‰", "æœ‰ç•°å‘³", "è‡­é…¸å‘³", "é…¸è‡­", 
    "è—¥æ°´å‘³", "æ¼‚ç™½æ°´å‘³", "åœŸå‘³", "æ²¹è€—å‘³", "è…æ•—",
    
    # ç‰©ç†æ€§èˆ‡å£æ„Ÿç•°å¸¸ (è§¸è¦º/è¦–è¦º)
    "æ²’ç†Ÿ", "æ²’ç…®ç†Ÿ", "è¡€æ°´", "åƒåˆ°é ­é«®", "åƒåˆ°èŸ‘è‚", "æœ‰èŸ²", 
    "ç¢ç»ç’ƒ", "é‹¼åˆ·çµ²", "ç•°ç‰©", "å¡‘è† ç‰‡", 

    # ç’°å¢ƒå•é¡Œ
    "è¡›ç”Ÿå•é¡Œ", "ç’°å¢ƒé«’äº‚"
]

# 2. é«˜é¢¨éšªæ–™ç†é—œéµå­—ï¼ˆæˆå“ã€èœåé¡ï¼‰
DISH_KEYWORDS = [
    "ç”Ÿé­šç‰‡", "åˆºèº«", "æ¡å£½å¸", "éŸƒé¼ç‰›è‚‰", "ç”Ÿç‰›è‚‰", "ç”Ÿé›è›‹", "è›‹æ¶²", "åŠç†Ÿè›‹", "å¤ªé™½è›‹", "æ³•å¼åå¸", "ç”Ÿèœæ²™æ‹‰",
    "ç”Ÿé†ƒ", "é†¬èŸ¹", "ææ‹‰ç±³è˜‡", "ç¾ä¹ƒæ»‹",
    "è¶Šå¼æ˜¥æ²", "ç”Ÿè ”",
]

# å°åŒ—å¸‚è¡Œæ”¿å€å°ç…§
DISTRICT_MAP = {
    "63000010": "æ¾å±±å€",
    "63000020": "ä¿¡ç¾©å€",
    "63000030": "å¤§å®‰å€",
    "63000040": "ä¸­å±±å€",
    "63000050": "ä¸­æ­£å€",
    "63000060": "å¤§åŒå€",
    "63000070": "è¬è¯å€",
    "63000080": "æ–‡å±±å€",
    "63000090": "å—æ¸¯å€",
    "63000100": "å…§æ¹–å€",
    "63000110": "å£«æ—å€",
    "63000120": "åŒ—æŠ•å€",
}


# ====================
# å®˜æ–¹è©•æ ¸è³‡æ–™è¼‰å…¥
# ====================
def load_certified_restaurants(csv_path: str) -> Dict[str, Dict[str, str]]:
    """
    è¼‰å…¥å®˜æ–¹é¤é£²è¡›ç”Ÿè©•æ ¸è³‡æ–™ï¼ˆåƒ…é™è©•æ ¸çµæœç‚ºã€Œå„ªã€ï¼‰
    
    Args:
        csv_path: CSV æª”æ¡ˆè·¯å¾‘
    
    Returns:
        ä»¥ã€Œæ¥­è€…åç¨±ã€ç‚º key çš„å­—å…¸
    """
    certified = {}
    total_count = 0
    excellent_count = 0
    good_count = 0
    
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            total_count += 1
            name = row.get("æ¥­è€…åç¨±åº—å", "").strip()
            rating = row.get("è©•æ ¸çµæœ", "").strip()
            
            if rating == "è‰¯":
                good_count += 1
                continue  # è·³éã€Œè‰¯ã€ç­‰ç´š
            
            if name and rating == "å„ª":
                excellent_count += 1
                district_code = row.get("è¡Œæ”¿å€åŸŸä»£ç¢¼", "")
                certified[name] = {
                    "district_code": district_code,
                    "district_name": DISTRICT_MAP.get(district_code, "æœªçŸ¥"),
                    "registration_id": row.get("é£Ÿå“æ¥­è€…ç™»éŒ„å­—è™Ÿ", ""),
                    "address": row.get("åœ°å€", ""),
                    "certification_rating": rating,
                }
    
    print(f"  åŸå§‹è³‡æ–™: {total_count} ç­†")
    print(f"  è©•æ ¸ã€Œå„ªã€: {excellent_count} ç­†ï¼ˆå·²ç´å…¥ï¼‰")
    print(f"  è©•æ ¸ã€Œè‰¯ã€: {good_count} ç­†ï¼ˆå·²æ’é™¤ï¼‰")
    
    return certified


def fuzzy_match_certification(
    restaurant_name: str,
    restaurant_address: str,
    certified_data: Dict[str, Dict[str, str]]
) -> Optional[Dict[str, str]]:
    """
    æ¨¡ç³Šæ¯”å°é¤å»³æ˜¯å¦åœ¨å®˜æ–¹èªè­‰åå–®ä¸­
    
    æ¯”å°ç­–ç•¥ï¼š
    1. å®Œå…¨åç¨±æ¯”å°
    2. æ¸…ç†å¾Œåç¨±æ¯”å°
    3. éƒ¨åˆ†åç¨± + åœ°å€äº¤å‰é©—è­‰
    
    Args:
        restaurant_name: é¤å»³åç¨±ï¼ˆä¾†è‡ª Google Placesï¼‰
        restaurant_address: é¤å»³åœ°å€ï¼ˆä¾†è‡ª Google Placesï¼‰
        certified_data: å®˜æ–¹èªè­‰è³‡æ–™å­—å…¸
    
    Returns:
        åŒ¹é…åˆ°çš„èªè­‰è³‡è¨Šï¼Œæˆ– None
    """
    if not restaurant_name:
        return None
    
    # ç­–ç•¥ 1ï¼šå®Œå…¨æ¯”å°
    if restaurant_name in certified_data:
        return certified_data[restaurant_name]
    
    # æ¸…ç†åç¨±ï¼ˆç§»é™¤å¸¸è¦‹å¾Œç¶´èˆ‡ç©ºç™½ï¼‰
    def clean_name(name: str) -> str:
        suffixes = ["é¤å»³", "åº—", "é–€å¸‚", "åˆ†åº—", "æ——è‰¦åº—", "æœ¬åº—", "ç¸½åº—"]
        result = name.strip()
        for suffix in suffixes:
            result = result.replace(suffix, "")
        return result.strip()
    
    clean_restaurant = clean_name(restaurant_name)
    
    # ç­–ç•¥ 2ï¼šæ¸…ç†å¾Œå®Œå…¨æ¯”å°
    for cert_name, cert_info in certified_data.items():
        if clean_restaurant == clean_name(cert_name):
            return cert_info
    
    # ç­–ç•¥ 3ï¼šéƒ¨åˆ†åç¨±æ¯”å° + åœ°å€é©—è­‰
    for cert_name, cert_info in certified_data.items():
        clean_cert = clean_name(cert_name)
        
        # æª¢æŸ¥åç¨±æ˜¯å¦æœ‰åŒ…å«é—œä¿‚
        name_match = (
            clean_restaurant in clean_cert or 
            clean_cert in clean_restaurant or
            clean_restaurant.replace("-", "") in clean_cert.replace("-", "")
        )
        
        if name_match:
            # æœ‰åœ°å€æ™‚é€²è¡Œäº¤å‰é©—è­‰
            if restaurant_address and cert_info["address"]:
                for district in DISTRICT_MAP.values():
                    if district in restaurant_address and district in cert_info["address"]:
                        return cert_info
            else:
                # ç„¡åœ°å€æ™‚ï¼Œè‹¥åç¨±ç›¸ä¼¼åº¦é«˜å‰‡ç›´æ¥åŒ¹é…
                if len(clean_restaurant) >= 3 and len(clean_cert) >= 3:
                    return cert_info
    
    return None


# ====================
# è©•è«–åˆ†æ
# ====================
def classify_review(review_text: str) -> Dict[str, Any]:
    """
    åˆ†æå–®å‰‡è©•è«–çš„é£Ÿå®‰é¢¨éšª
    
    Args:
        review_text: è©•è«–å…§æ–‡
    
    Returns:
        {
            "has_symptoms": bool,
            "has_raw_food": bool,
            "matched_keywords": List[str],
        }
    """
    if not review_text:
        return {
            "has_symptoms": False,
            "has_raw_food": False,
            "matched_keywords": [],
        }
    
    text = review_text.lower()
    matched = []
    
    # æª¢æŸ¥è² é¢ç—‡ç‹€
    has_symptoms = False
    for keyword in SYMPTOM_KEYWORDS:
        if keyword in text:
            has_symptoms = True
            matched.append(f"ç—‡ç‹€:{keyword}")
    
    # æª¢æŸ¥ç”Ÿé£Ÿé—œéµå­—
    has_raw_food = False
    for keyword in DISH_KEYWORDS:
        if keyword in text:
            has_raw_food = True
            matched.append(f"ç”Ÿé£Ÿ:{keyword}")
    
    return {
        "has_symptoms": has_symptoms,
        "has_raw_food": has_raw_food,
        "matched_keywords": matched,
    }


def classify_restaurant(
    restaurant: Dict[str, Any],
    certified_data: Dict[str, Dict[str, str]]
) -> Dict[str, Any]:
    """
    åˆ†æå–®å®¶é¤å»³çš„æ•´é«”é£Ÿå®‰é¢¨éšªï¼ˆæ•´åˆå®˜æ–¹èªè­‰ï¼‰
    
    Args:
        restaurant: é¤å»³è³‡æ–™ï¼ˆå«è©•è«–ï¼‰
        certified_data: å®˜æ–¹èªè­‰è³‡æ–™å­—å…¸
    
    Returns:
        åŸé¤å»³è³‡æ–™ + safety_analysis æ¬„ä½
    """
    reviews = restaurant.get("reviews", [])
    name = restaurant.get("name", "")
    address = restaurant.get("formatted_address", "")
    
    # æª¢æŸ¥å®˜æ–¹èªè­‰
    certification = fuzzy_match_certification(name, address, certified_data)
    
    # åˆ†ææ‰€æœ‰è©•è«–
    all_matched_keywords = []
    symptom_count = 0
    raw_food_count = 0
    flagged_reviews = []
    
    for review in reviews:
        text = review.get("text", "")
        result = classify_review(text)
        
        if result["has_symptoms"]:
            symptom_count += 1
            flagged_reviews.append({
                "type": "ç—‡ç‹€",
                "author": review.get("author_name", "åŒ¿å"),
                "text_preview": text[:100] + "..." if len(text) > 100 else text,
                "keywords": [k for k in result["matched_keywords"] if k.startswith("ç—‡ç‹€:")],
            })
        
        if result["has_raw_food"]:
            raw_food_count += 1
        
        all_matched_keywords.extend(result["matched_keywords"])
    
    # åˆ¤å®šé¢¨éšªç­‰ç´š
    # å„ªå…ˆç´šï¼šç—‡ç‹€ > å®˜æ–¹èªè­‰ > ç”Ÿé£Ÿ > ä½é¢¨éšª
    if symptom_count > 0:
        level = SafetyLevel.HIGH_RISK
    elif certification:
        level = SafetyLevel.CERTIFIED
    elif raw_food_count > 0:
        level = SafetyLevel.MEDIUM_RISK
    else:
        level = SafetyLevel.LOW_RISK
    
    # çµ„è£åˆ†æçµæœ
    safety_analysis = {
        "level": level.value,
        "symptom_mentions": symptom_count,
        "raw_food_mentions": raw_food_count,
        "matched_keywords": list(set(all_matched_keywords)),
        "total_reviews_analyzed": len(reviews),
        "flagged_reviews": flagged_reviews if flagged_reviews else None,
        "official_certification": None,
    }
    
    if certification:
        safety_analysis["official_certification"] = {
            "status": "é€šéè©•æ ¸",
            "rating": certification["certification_rating"],
            "registration_id": certification["registration_id"],
            "certified_address": certification["address"],
            "district": certification["district_name"],
        }
    
    return {
        **restaurant,
        "safety_analysis": safety_analysis,
    }


# ====================
# ä¸»æµç¨‹
# ====================
def process_all_restaurants(
    input_path: str,
    output_path: str,
    certification_csv_path: str
) -> List[Dict[str, Any]]:
    """
    ä¸»æµç¨‹ï¼šè®€å–åŸå§‹è³‡æ–™ â†’ è¼‰å…¥å®˜æ–¹èªè­‰ â†’ åˆ†é¡ â†’ è¼¸å‡º
    
    Args:
        input_path: çˆ¬èŸ²è³‡æ–™ JSON è·¯å¾‘
        output_path: è¼¸å‡º JSON è·¯å¾‘
        certification_csv_path: å®˜æ–¹è©•æ ¸ CSV è·¯å¾‘
    
    Returns:
        åˆ†é¡å¾Œçš„é¤å»³æ¸…å–®
    """
    print("=" * 50)
    print("é£Ÿå“å®‰å…¨é¢¨éšªåˆ†ç´šç³»çµ±")
    print("=" * 50)
    
    # Step 1: è¼‰å…¥å®˜æ–¹èªè­‰è³‡æ–™
    print("\nStep 1: è¼‰å…¥å®˜æ–¹é¤é£²è¡›ç”Ÿè©•æ ¸è³‡æ–™...")
    if not os.path.exists(certification_csv_path):
        print(f"  è­¦å‘Šï¼šæ‰¾ä¸åˆ°å®˜æ–¹è©•æ ¸è³‡æ–™ ({certification_csv_path})")
        print("   å°‡åƒ…ä¾æ“šè©•è«–å…§å®¹é€²è¡Œåˆ†é¡")
        certified_data = {}
    else:
        certified_data = load_certified_restaurants(certification_csv_path)
    
    # Step 2: è¼‰å…¥çˆ¬èŸ²è³‡æ–™
    print(f"\nStep 2: è¼‰å…¥çˆ¬èŸ²è³‡æ–™...")
    if not os.path.exists(input_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°çˆ¬èŸ²è³‡æ–™: {input_path}")
    
    with open(input_path, "r", encoding="utf-8") as f:
        restaurants = json.load(f)
    print(f"   å…± {len(restaurants)} å®¶é¤å»³å¾…åˆ†é¡")
    
    # Step 3: åŸ·è¡Œåˆ†é¡
    print(f"\n Step 3: åŸ·è¡Œé£Ÿå®‰é¢¨éšªåˆ†é¡...")
    classified = []
    for i, restaurant in enumerate(restaurants, 1):
        result = classify_restaurant(restaurant, certified_data)
        classified.append(result)
        
        # é€²åº¦é¡¯ç¤º
        if i % 10 == 0 or i == len(restaurants):
            print(f"   é€²åº¦: {i}/{len(restaurants)}")
    
    # Step 4: æ’åºï¼ˆæ¨è–¦é †åºï¼šå®˜æ–¹èªè­‰ > ä½é¢¨éšª > ä¸­é¢¨éšª > é«˜é¢¨éšªï¼‰
    level_order = {
        SafetyLevel.CERTIFIED.value: 0,
        SafetyLevel.LOW_RISK.value: 1,
        SafetyLevel.MEDIUM_RISK.value: 2,
        SafetyLevel.HIGH_RISK.value: 3,
    }
    classified.sort(key=lambda x: (
        level_order[x["safety_analysis"]["level"]],
        -x.get("rating", 0)  # åŒç­‰ç´šå…§ä¾ Google è©•åˆ†æ’åº
    ))
    
    # Step 5: å„²å­˜çµæœ
    print(f"\n Step 4: å„²å­˜åˆ†é¡çµæœ...")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(classified, f, ensure_ascii=False, indent=2)
    
    # Step 6: è¼¸å‡ºæ‘˜è¦
    print("\n" + "=" * 50)
    print("åˆ†é¡çµæœæ‘˜è¦")
    print("=" * 50)
    
    level_emoji = {
        "å®˜æ–¹èªè­‰": "âœ…",
        "ç„¡/ä½é¢¨éšª": "ğŸŸ¢",
        "ä¸­é¢¨éšª": "ğŸŸ¡",
        "é«˜é¢¨éšª": "ğŸ”´",
    }
    
    for level in SafetyLevel:
        count = sum(1 for r in classified if r["safety_analysis"]["level"] == level.value)
        emoji = level_emoji.get(level.value, "")
        print(f"   {emoji} {level.value}: {count} å®¶")
    
    # é«˜é¢¨éšªé¤å»³è©³æƒ…
    high_risk = [r for r in classified if r["safety_analysis"]["level"] == "é«˜é¢¨éšª"]
    if high_risk:
        print("\n  é«˜é¢¨éšªé¤å»³è­¦ç¤ºï¼š")
        for r in high_risk:
            name = r.get("name", "æœªçŸ¥")
            keywords = r["safety_analysis"]["matched_keywords"]
            symptom_keywords = [k.replace("ç—‡ç‹€:", "") for k in keywords if k.startswith("ç—‡ç‹€:")]
            print(f"   - {name}")
            print(f"     é—œéµå­—: {', '.join(symptom_keywords)}")
    
    print("\n" + "=" * 50)
    print(f" å®Œæ•´çµæœå·²å„²å­˜è‡³: {output_path}")
    print(f"åˆ†é¡æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    return classified


# ====================
# é€²å…¥é»
# ====================
if __name__ == "__main__":
    # é è¨­è·¯å¾‘é…ç½®
    INPUT_PATH = "data/raw/places_with_reviews.json"
    OUTPUT_PATH = "data/processed/safety_classified.json"
    CERTIFICATION_CSV = "data/external/certified_restaurants.csv"
    
    try:
        process_all_restaurants(
            input_path=INPUT_PATH,
            output_path=OUTPUT_PATH,
            certification_csv_path=CERTIFICATION_CSV,
        )
    except FileNotFoundError as e:
        print(f" éŒ¯èª¤: {e}")
        print("\nè«‹ç¢ºèªä»¥ä¸‹æª”æ¡ˆå­˜åœ¨ï¼š")
        print(f"   1. {INPUT_PATH}")
        print(f"   2. {CERTIFICATION_CSV}")
    except Exception as e:
        print(f" æœªé æœŸçš„éŒ¯èª¤: {e}")
        raise